ğŸ—£ï¸ STT_Whisper

Real-time Speech-to-Text Command Recognition using Faster-Whisper

ğŸš€ Overview

STT_Whisper is a lightweight real-time speech-to-text command system built on top of Faster-Whisper.
It captures audio from the microphone, detects voice activity using an energy-based VAD, transcribes speech locally, and classifies recognized text into high-level commands (e.g., start/stop) using keyword rules.

This project is fully optimized for CPU-only environments, making it ideal for desktop applications, kiosks, and edge devices without a GPU.

âœ¨ Features

ğŸ¤ Real-time microphone streaming using sounddevice

ğŸ”‡ Energy-based VAD to skip silent sections and reduce computation

âš¡ Fast and efficient speech recognition with Faster-Whisper (ONNX runtime)

ğŸ” Customizable command classification with keyword rules

ğŸ’» Runs entirely offline (local inference)

ğŸ§© Easy to integrate into other automation or UI control systems

ğŸ› ï¸ Installation
1) Clone Repository
git clone https://github.com/USER/STT_Whisper.git
cd STT_Whisper

2) Install Dependencies
ğŸ”¹ Python version check
python3 --version

ğŸ”¹ Install FFmpeg (Linux)
sudo apt update
sudo apt install -y ffmpeg libportaudio2

ğŸ”¹ Install Python packages
python3 -m pip install --upgrade pip
pip install onnxruntime onnxruntime-tools
pip install faster-whisper sounddevice scipy


Windowsì—ì„œëŠ” ë‹¤ìŒë§Œ ì„¤ì¹˜í•˜ë©´ ë©ë‹ˆë‹¤:

pip install faster-whisper sounddevice scipy

â–¶ï¸ Usage

Run the real-time STT program:

python3 stt_whisper.py


You will see something like:

ğŸ¤ Real-time speech recognition started
ğŸ¯ Recognized: start
â–¶ Start action triggered

ğŸ¯ Recognized: stop
â¹ Stop action triggered


Default commands included:

start, ì‹œì‘, go

stop, ì •ì§€, ë©ˆì¶°

You can easily modify the keywords inside the source code.

ğŸ“¦ Project Structure
STT_Whisper/
 â”œâ”€â”€ stt_whisper.py     # Main real-time STT engine
 â”œâ”€â”€ README.md
 â”œâ”€â”€ requirements.txt   # (optional)
 â””â”€â”€ ...

ğŸ§  Technology Behind This Project
ğŸ”¹ Whisper

Whisper is an open-source multilingual speech recognition model by OpenAI.
It supports dozens of languages, handles noisy environments well, and works entirely offline.

ğŸ”¹ Faster-Whisper

A highly optimized implementation of Whisper.

2â€“4Ã— faster than original Whisper

Lower memory usage

Ideal for CPU-based applications

Uses ONNX Runtime for improved performance

This project uses Whisper small-int8, balancing speed and accuracy.

ğŸ“Œ Future Improvements (Optional Ideas)

Add GUI control panel

Add WebSocket API for external integration

Add wake-word detection (e.g., â€œHey Whisperâ€)

Export recognized text to other services (MQTT, REST API, etc.)

ğŸ¤ Contributing

Issues and PRs are welcome! Feel free to improve command rules, VAD logic, or add more features.

ğŸ“„ License

MIT License.
